{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as imagev\n",
    "import numpy as np\n",
    "from tensorflow import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image as ImageBuilder\n",
    "from PIL.Image import Image\n",
    "from keras import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def load_data():\n",
    "    x, y = [], []\n",
    "    for path in[*list(Path('./data').glob(\"*.jpg\"))]:\n",
    "        x.append(read_and_reshape_image(path))\n",
    "        y.append(int(path.name.split(\".\")[0]))\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def read_and_reshape_image(image_path, grayscale=True):\n",
    "  img = Image.open(image_path)\n",
    "\n",
    "  if grayscale:\n",
    "    img = ImageOps.grayscale(img)\n",
    "\n",
    "  img = img.resize((28, 28))\n",
    "  \n",
    "  img = np.array(img) / 255\n",
    "  # img_data = np.array(img).reshape(784)\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Преобразование данных в формат, подходящий для CNN\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = utils.to_categorical(y_train, 10)\n",
    "Y_test = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 - 148s - loss: 0.1868 - accuracy: 0.9420 - val_loss: 0.0505 - val_accuracy: 0.9840 - 148s/epoch - 274ms/step\n",
      "Epoch 2/10\n",
      "540/540 - 162s - loss: 0.0541 - accuracy: 0.9842 - val_loss: 0.0379 - val_accuracy: 0.9883 - 162s/epoch - 299ms/step\n",
      "Epoch 3/10\n",
      "540/540 - 165s - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0319 - val_accuracy: 0.9908 - 165s/epoch - 305ms/step\n",
      "Epoch 4/10\n",
      "540/540 - 191s - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0407 - val_accuracy: 0.9900 - 191s/epoch - 353ms/step\n",
      "Epoch 5/10\n",
      "540/540 - 138s - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0368 - val_accuracy: 0.9905 - 138s/epoch - 256ms/step\n",
      "Epoch 6/10\n",
      "540/540 - 106s - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.0302 - val_accuracy: 0.9925 - 106s/epoch - 196ms/step\n",
      "Epoch 7/10\n",
      "540/540 - 97s - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0351 - val_accuracy: 0.9918 - 97s/epoch - 180ms/step\n",
      "Epoch 8/10\n",
      "540/540 - 96s - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0344 - val_accuracy: 0.9922 - 96s/epoch - 178ms/step\n",
      "Epoch 9/10\n",
      "540/540 - 106s - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0463 - val_accuracy: 0.9917 - 106s/epoch - 196ms/step\n",
      "Epoch 10/10\n",
      "540/540 - 102s - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0310 - val_accuracy: 0.9920 - 102s/epoch - 189ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24036c00cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=100,\n",
    "              epochs=10,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 399ms/step - loss: 4.7067 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.706671714782715, 0.10000000149011612]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_data()\n",
    "\n",
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо переобучилась"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
